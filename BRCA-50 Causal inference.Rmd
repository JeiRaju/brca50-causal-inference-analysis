---
title: "BRCA-50: Causal Gene Network & Classification Analysis"
author: "Jei Pratheesh"
date: "2025-04-19"
output: pdf_document
---

# 1. Causal Structure Learning

## 1.1 Introduction

The aim of this project is to discover causal structures among 50 important breast cancer genes (BRCA-50 dataset) using Bayesian network learning methods. Specifically, I've decided to apply the **PC algorithm** (Peter-Clark algorithm), a constraint-based causal structure learning method, to infer gene regulatory networks.

## 1.2 Data Preprocessing

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# Load required packages
library(bnlearn)
library(pcalg)
library(Rgraphviz)
library(rmarkdown)
library(tinytex)

# Load the dataset
gene_data <- read.csv("BRCA_RNASeqv2_top50.csv", header = TRUE)

# Remove the class variable (normal/cancer labels) as instructed
gene_data_noclass <- gene_data[, -which(names(gene_data) == "class")]

# Display the dimensions of the data
dim(gene_data_noclass)
```

## 1.3 Apply PC Algorithm

```{r pc-algorithm}
# Prepare sufficient statistics for continuous data
suffStat <- list(C = cor(gene_data_noclass), n = nrow(gene_data_noclass))

# Apply the PC algorithm
pc.fit <- pc(suffStat = suffStat, indepTest = gaussCItest, alpha = 0.01, labels = colnames(gene_data_noclass))

# Plot the resulting CPDAG (Completed Partially Directed Acyclic Graph)
plot(pc.fit@graph)
```
The above diagram was generated using the `pc()` algorithm, producing a **Completed Partially Directed Acyclic Graph (CPDAG)**. It reflects the estimated causal relationships among the 50 genes (excluding the class label):

### Interpretation:

- Based on the above graph only **Directed edges** are present and they represent the potential direct causal influences from gene to gene.
- The graph is quite dense, suggesting **high inter-connectivity among genes**.
- Some genes appear to have multiple incoming/outgoing connections, hinting at their potential centrality in the regulatory structure.

---

# 2. Causal Inference on ABCA9

## 2.1 IDA Method Introduction

The **IDA (Intervention calculus when DAG is Absent)** method allows estimation of causal effects from observational data based on the CPDAG output of the PC algorithm 【63†source】【64†source】.

- **Input**: Graph from PC algorithm, covariance matrix, and target variable.
- **Output**: Estimated causal effects.

## 2.2 Apply IDA on ABCA9

```{r ida-abca9}
# Find the index of ABCA9 gene
abca9_index <- which(colnames(gene_data_noclass) == "ABCA9")

# Create empty vector to store effects
ida_results <- numeric(ncol(gene_data_noclass))

# Loop through all potential cause genes (excluding ABCA9 itself)
for (i in 1:ncol(gene_data_noclass)) {
  if (i == abca9_index) {
    ida_results[i] <- 0  # No self-effect
  } else {
    ida_val <- tryCatch(
      {
        ida(i, abca9_index, cov(gene_data_noclass), pc.fit@graph, method = "local")
      },
      error = function(e) NA
    )
    ida_results[i] <- ifelse(is.null(ida_val), NA, ida_val)
  }
}

# Create a table of causal effects
causal_effects <- data.frame(Gene = colnames(gene_data_noclass), Effect = ida_results)

# Rank by the absolute value of causal effects
causal_effects$AbsEffect <- abs(causal_effects$Effect)
causal_effects <- causal_effects[order(-causal_effects$AbsEffect), ]

# Display top 10 causes
head(causal_effects, 10)
```

## 2.3 Top 10 Strongest Causes Table

The above table lists the top 10 genes which causally influence **ABCA9** based on absolute causal effect values in descending order.

### Interpretation of the Output of Top 10 Causal Gene table

The table above shows the output of the 10 genes with the highest causal effect on **ABCA9** in descending order.

---

# 3. Local Causal Structure Learning for EBF1

## 3.1 IAMB Algorithm Introduction

The **IAMB (Incremental Association Markov Blanket)** algorithm is a constraint-based local structure learning method implemented in the `bnlearn` package. It identifies the **Markov Blanket** of a target variable by incrementally including and removing features based on conditional independence tests.

The Markov Blanket includes:
- The parents of the node,
- The children of the node,
- And other parents of its children.

## 3.2 Apply IAMB Algorithm to EBF1

```{r iamb-ebf1}
# Run IAMB to find Markov Blanket of EBF1
iamb_ebf1 <- learn.mb(gene_data_noclass,"EBF1", method = "iamb", alpha=0.01)
iamb_ebf1
```

## 3.3 Genes in Markov Blanket of EBF1

The genes returned represent the **Markov Blanket** of EBF1 according to the IAMB algorithm. These are variables that either influence EBF1 directly or share common children with it, and form the smallest set of variables that makes EBF1 conditionally independent of all others.

The listed genes are the likely direct causes, direct effects, or co-parents of EBF1.
Understanding the Markov Blanket helps prioritize genes for further biological validation.

---

# 4. Naïve Bayes Classification: Full vs PC-Set

## 4.1 Objective

We compare classification accuracy using:
- **All genes** as predictors (baseline)
- **Only the parent and children set of the class variable** (discovered using PC-Simple)

We apply **Naïve Bayes classification with 5-fold cross-validation**.

## 4.2 Discretisation

```{r discretise}
# Compute the average expression value across all genes and all samples
overall_mean <- mean(as.matrix(gene_data_noclass))

# Discretise genes into binary (0 = Low, 1 = High) based on overall mean
disc_genes <- gene_data_noclass
for (col in colnames(disc_genes)) {
  disc_genes[[col]] <- ifelse(disc_genes[[col]] > overall_mean, 1, 0)
}

# Combine discretised gene data with the original class label
disc_data <- cbind(disc_genes, class = as.factor(gene_data$class))
```

## 4.3 PC-Simple: Discover Parent/Children of Class

```{r pc-simple-class}
# Prepare numeric version for PC-simple
disc_data_classnum <- disc_data
disc_data_classnum$class <- as.numeric(disc_data_classnum$class)

# Run PC-simple to find PC set of 'class'
pc_class <- pcSelect(disc_data_classnum$class,
                      disc_data_classnum[, -which(names(disc_data_classnum) == "class")],
                      alpha = 0.05)

pc_genes <- colnames(disc_data_classnum)[-which(colnames(disc_data_classnum) == "class")][which(pc_class$G)]
pc_genes
```

## 4.4 5-Fold Cross-Validation: All Genes vs PC Genes

```{r nb-classification}
set.seed(42)
folds <- createFolds(disc_data$class, k = 5)

acc_all <- c()
acc_pc <- c()

for (i in 1:5) {
  train_idx <- unlist(folds[-i])
  test_idx <- unlist(folds[i])

  # Full model
  model_all <- naiveBayes(class ~ ., data = disc_data[train_idx, ])
  pred_all <- predict(model_all, disc_data[test_idx, ])
  acc_all[i] <- mean(pred_all == disc_data[test_idx, ]$class)

  # PC model
  model_pc <- naiveBayes(x = disc_data[train_idx, pc_genes], y = disc_data[train_idx, ]$class)
  pred_pc <- predict(model_pc, disc_data[test_idx, pc_genes])
  acc_pc[i] <- mean(pred_pc == disc_data[test_idx, ]$class)
}

# Report average accuracy
mean(acc_all)
mean(acc_pc)
```

## 4.5 Interpretation

- The **full model** uses all gene features, which may lead to overfitting or include noisy genes.
- The **PC-set model** focuses only on genes that are directly linked to the class variable.
- Comparing accuracies helps assess whether causal feature selection improves generalisation.
- Using all genes for classification achieved a mean accuracy of **95.38%**.  
- However, selecting only the parents and children of the class variable via PC-Simple and using them as features resulted in a higher mean accuracy of **98.27%**.
- This demonstrates that causal feature selection can improve classification performance by reducing noise and focusing on the most relevant features.  
- It suggests that many genes may not contribute useful information for predicting the class label, and that targeting a causally-relevant subset can lead to simpler and more accurate models.

---

# 5. Bayesian Network Inference (Based on Provided Structure)

## 5a. Construct Conditional Probability Tables (CPTs)

```{r construct-cpts}
# Select relevant genes for the Bayesian network
disc_selected <- disc_data[, c("CD300LG", "BTNL9", "IGSF10", "ABCA9", "class")]

# Compute CPTs
cpt_cd300lg <- table(disc_selected$CD300LG) / nrow(disc_selected)
cpt_btnl9_given_cd300lg <- prop.table(table(disc_selected$BTNL9, disc_selected$CD300LG), margin = 2)
cpt_class_given_cd300lg <- prop.table(table(disc_selected$class, disc_selected$CD300LG), margin = 2)
cpt_igsf10_given_class <- prop.table(table(disc_selected$IGSF10, disc_selected$class), margin = 2)
cpt_abca9_given_igsf10_btnl9 <- prop.table(table(disc_selected$ABCA9, disc_selected$IGSF10, disc_selected$BTNL9), margin = c(2, 3))

# Display CPTs
cpt_cd300lg
cpt_btnl9_given_cd300lg
cpt_class_given_cd300lg
cpt_igsf10_given_class
cpt_abca9_given_igsf10_btnl9
```

## 5b. Estimate Probability: All Genes High

```{r probability-all-high}
# Compute P(CD300LG=1) * P(BTNL9=1|CD300LG=1) * P(class=C|CD300LG=1) * P(IGSF10=1|class=C) * P(ABCA9=1|IGSF10=1, BTNL9=1)

p_cd300lg_1 <- cpt_cd300lg["1"]
p_btnl9_1_given_cd300lg_1 <- cpt_btnl9_given_cd300lg["1", "1"]
p_class_c_given_cd300lg_1 <- cpt_class_given_cd300lg["C", "1"]
p_igsf10_1_given_class_c <- cpt_igsf10_given_class["1", "C"]
p_abca9_1_given_igsf10_1_btnl9_1 <- cpt_abca9_given_igsf10_btnl9["1", "1", "1"]

p_joint_all_high <- p_cd300lg_1 * p_btnl9_1_given_cd300lg_1 * p_class_c_given_cd300lg_1 * p_igsf10_1_given_class_c * p_abca9_1_given_igsf10_1_btnl9_1

p_joint_all_high
```

## 5c. Estimate Probability: Cancer given CD300LG High, BTNL9 Low

To estimate the probability of having cancer when CD300LG = High (1) and BTNL9 = Low (0), we consider the structure of the Bayesian network.

In the given structure, class is a direct child of CD300LG and does not have BTNL9 as a parent. This means that class depends only on CD300LG and is conditionally independent of BTNL9 given CD300LG.

Thus, the conditional probability P(class = C | CD300LG = 1, BTNL9 = 0) simplifies to P(class = C | CD300LG = 1).

```{r probability-cancer}
# Extract P(class = C | CD300LG = 1) directly from CPT
p_class_c_given_cd300lg_1 <- cpt_class_given_cd300lg["C", "1"]
p_class_c_given_cd300lg_1
```

The resulting probability is approximately **0.2585**.

---

## 5d. Mathematical Proof for 5c

We aim to justify mathematically that:

**P(class = C | CD300LG = 1, BTNL9 = 0) = P(class = C | CD300LG = 1)**

This equality holds based on the structure of the Bayesian network and the properties of d-separation.

In the provided Bayesian network, the variable class is only conditionally dependent on CD300LG, meaning CD300LG is its only parent node. BTNL9 is not a parent nor a child of class. Therefore, by the **Markov condition**, class is conditionally independent of any non-descendant node given its parent.

Hence, we conclude:

**P(class = C | CD300LG = 1, BTNL9 = 0) = P(class = C | CD300LG = 1)**

The result used in part 5c is therefore validated mathematically by the network’s conditional independence assumptions.

---